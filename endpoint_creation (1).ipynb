{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb8f950-8603-441d-ac68-ae8e868d2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found in S3:\n",
      "deberta-finetuned-model/added_tokens.json\n",
      "deberta-finetuned-model/config.json\n",
      "deberta-finetuned-model/model.safetensors\n",
      "deberta-finetuned-model/model.tar.gz\n",
      "deberta-finetuned-model/special_tokens_map.json\n",
      "deberta-finetuned-model/spm.model\n",
      "deberta-finetuned-model/tokenizer.json\n",
      "deberta-finetuned-model/tokenizer_config.json\n",
      "deberta-finetuned-model/training_args.bin\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3_bucket = \"sagemaker-us-east-1-198739141498\"  # Change this\n",
    "s3_prefix = \"deberta-finetuned-model/\"  # Change this\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix)\n",
    "\n",
    "if \"Contents\" in response:\n",
    "    print(\"Files found in S3:\")\n",
    "    for obj in response[\"Contents\"]:\n",
    "        print(obj[\"Key\"])\n",
    "else:\n",
    "    print(\"❌ No files found! Check your S3 path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c57d79-0506-43e7-afe2-41f470a4f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "model_dir = \"trained_model\"  # Folder where your trained model is stored\n",
    "output_filename = \"model.tar.gz\"\n",
    "\n",
    "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "    tar.add(model_dir, arcname=\".\")\n",
    "\n",
    "print(f\"✅ Created {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e6f051-c4c4-4571-981c-7547cc10491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded model.tar.gz to s3://sagemaker-us-east-1-198739141498/deberta-finetuned-model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3_bucket = \"sagemaker-us-east-1-198739141498\"  # Change to your actual bucket\n",
    "s3_key = \"deberta-finetuned-model/model.tar.gz\"\n",
    "\n",
    "# s3_client = boto3.client(\"s3\")\n",
    "# s3_client.upload_file(\"model.tar.gz\", s3_bucket, s3_key)\n",
    "\n",
    "print(f\"✅ Uploaded model.tar.gz to s3://{s3_bucket}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93802a12-ac4f-41cd-a2b6-2749f8516aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found in S3:\n",
      "deberta-finetuned-model/added_tokens.json\n",
      "deberta-finetuned-model/config.json\n",
      "deberta-finetuned-model/model.safetensors\n",
      "deberta-finetuned-model/model.tar.gz\n",
      "deberta-finetuned-model/special_tokens_map.json\n",
      "deberta-finetuned-model/spm.model\n",
      "deberta-finetuned-model/tokenizer.json\n",
      "deberta-finetuned-model/tokenizer_config.json\n",
      "deberta-finetuned-model/training_args.bin\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=\"deberta-finetuned-model/\")\n",
    "if \"Contents\" in response:\n",
    "    print(\"Files found in S3:\")\n",
    "    for obj in response[\"Contents\"]:\n",
    "        print(obj[\"Key\"])\n",
    "else:\n",
    "    print(\"❌ No files found! Check your S3 path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f8c747b-1cd5-4670-89b7-4c605fec08ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 13:05:41] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Repacking model artifact                                                  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/model.py#819\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">819</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//sagemaker-us-east-1-198739141498/deberta-finetuned-model/model.tar.</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">gz</span><span style=\"font-weight: bold\">)</span>, script artifact <span style=\"font-weight: bold\">(</span>.<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/model_inf</span><span style=\"font-weight: bold\">)</span>, and dependencies <span style=\"font-weight: bold\">([])</span> into single     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         tar.gz file located at                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//sagemaker-us-east-1-198739141498/pytorch-inference-2025-02-06-13-05-</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">41-469/model.tar.gz.</span> This may take some time depending on model size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 13:05:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Repacking model artifact                                                  \u001b]8;id=975724;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=298337;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/model.py#819\u001b\\\u001b[2m819\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0ms3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/sagemaker-us-east-1-198739141498/deberta-finetuned-model/\u001b[0m\u001b[38;2;225;0;225mmodel.tar.\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225mgz\u001b[0m\u001b[1m)\u001b[0m, script artifact \u001b[1m(\u001b[0m.\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225mmodel_inf\u001b[0m\u001b[1m)\u001b[0m, and dependencies \u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m into single     \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         tar.gz file located at                                                    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         s3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/sagemaker-us-east-1-198739141498/pytorch-inference-2025-02-06-13-05-\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225m41-469/\u001b[0m\u001b[38;2;225;0;225mmodel.tar.gz.\u001b[0m This may take some time depending on model size\u001b[33m...\u001b[0m   \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 13:09:21] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: pytorch-inference-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-06-13-09-21-509    <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 13:09:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: pytorch-inference-\u001b[1;36m2025\u001b[0m-02-06-13-09-21-509    \u001b]8;id=423182;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=869018;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/06/25 13:09:22] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pytorch-inference-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-06-13-09-22-240                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/06/25 13:09:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=865708;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=62588;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         pytorch-inference-\u001b[1;36m2025\u001b[0m-02-06-13-09-22-240                              \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name pytorch-inference-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-06-13-09-22-240  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name pytorch-inference-\u001b[1;36m2025\u001b[0m-02-06-13-09-22-240  \u001b]8;id=834300;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=297619;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!Model deployed successfully!\n",
      "Endpoint Name: pytorch-inference-2025-02-06-13-09-22-240\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "# Define your S3 bucket name\n",
    "s3_bucket = \"sagemaker-us-east-1-198739141498\"\n",
    "s3_model_path = f\"s3://{s3_bucket}/deberta-finetuned-model/model.tar.gz\"\n",
    "# Define IAM role\n",
    "role = \"arn:aws:iam::198739141498:role/ClaimCat-SageMaker-Execution-Role\"\n",
    "# Define model name\n",
    "model_name = \"deberta-finetuned-model\"\n",
    "# Create SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Create the SageMaker PyTorch model\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_path,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"./model_inf\", # Directory containing inference.py\n",
    "    framework_version=\"1.12.1\",\n",
    "    py_version=\"py38\",\n",
    "    predictor_cls=sagemaker.predictor.Predictor\n",
    ")\n",
    "# Deploy the model with error handling\n",
    "try:\n",
    "    predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    "    )\n",
    "    print(\"Model deployed successfully!\")\n",
    "    print(f\"Endpoint Name: {predictor.endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Deployment failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b084a87-a53b-4fed-8755-9e857f5464a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Name: pytorch-inference-2025-02-06-13-09-22-240\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# List all endpoints\n",
    "endpoints = sagemaker_client.list_endpoints()\n",
    "\n",
    "# Print all endpoint names\n",
    "for ep in endpoints[\"Endpoints\"]:\n",
    "    print(\"Endpoint Name:\", ep[\"EndpointName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4c968-5e3b-4cb2-9857-d250f8b12c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Define the SageMaker endpoint\n",
    "ENDPOINT_NAME = \"pytorch-inference-2025-02-06-13-09-22-240\"\n",
    "\n",
    "# Example input text\n",
    "input_text = \"The new 5G technology is improving telecommunications.\"\n",
    "\n",
    "# Format the input data as JSON\n",
    "payload = json.dumps({\"inputs\": input_text})\n",
    "\n",
    "# Invoke the SageMaker endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,  # Your SageMaker endpoint name\n",
    "    ContentType=\"application/json\",\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "# Read and parse the response\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "\n",
    "print(\"Model Response:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4e8c9-ae9c-40c2-a39d-9effe3f221a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
